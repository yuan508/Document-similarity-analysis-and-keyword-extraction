

# 📖 文档相似度分析方法

### 1. **TF-IDF + Cosine Similarity**

* **核心思想**：
  用 TF-IDF 将文本转为向量，再计算余弦相似度衡量文档间的相似度：

  $$
  \text{cosine}(A,B) = \frac{A \cdot B}{||A|| \times ||B||}
  $$

* **例子**：

  * 文档1: `"我喜欢自然语言处理"`
  * 文档2: `"自然语言处理是人工智能的核心"`
  * 转化为 TF-IDF 向量后，计算余弦值，结果接近 0.6，说明两者有一定相似度。

* **优点**：

  * 实现简单，效果稳定
  * 常用于信息检索与文本分类

* **缺点**：

  * 高维稀疏向量 → 计算开销大
  * 无法理解语义，只依赖词频

---

### 2. **Gensim TF-IDF + SparseMatrixSimilarity**

* **核心思想**：
  使用 Gensim 构建字典和 TF-IDF 模型，再利用 `SparseMatrixSimilarity` 建立索引，实现大规模语料的快速相似度计算。

* **例子**：

  * 构建语料：`["我喜欢自然语言处理", "自然语言处理是人工智能的核心"]`
  * 用 Gensim 训练 TF-IDF 模型
  * 输入新查询 `"我研究人工智能"` → 得到与每个文档的相似度，比如：

    * 与文档1 相似度 0.3
    * 与文档2 相似度 0.7

* **优点**：

  * 内置高效相似度索引
  * 适合大语料规模

* **缺点**：

  * 需要额外训练和建模步骤
  * 与 sklearn 一样缺乏语义信息

---

### 3. **SimHash + Hamming Distance**

* **核心思想**：
  将文档映射成固定长度的二进制哈希指纹（SimHash），用 Hamming 距离来衡量两个哈希的差异。

* **例子**：

  * 文档1: `"我喜欢自然语言处理"` → SimHash: `1011010101...`
  * 文档2: `"我研究自然语言处理"` → SimHash: `1011011101...`
  * Hamming 距离 = 2（只有两个比特不同） → 高度相似

* **优点**：

  * 极其高效，适合海量文本去重与近似检索
  * 对部分改动（如增加/替换少量词）有容错性

* **缺点**：

  * 只能检测粗粒度相似性
  * 无法区分深层语义相似

---

# 🔑 关键词提取方法

### 1. **TF-IDF (Term Frequency–Inverse Document Frequency)**

* **核心思想**：
  通过计算词语在文档中的出现频率（TF），结合其在所有文档中的普遍性（IDF），衡量词语对该文档的重要程度。公式如下：

  $$
  TFIDF(w, d) = TF(w, d) \times IDF(w)
  $$

  其中：

  * $TF(w, d)$：词 $w$ 在文档 $d$ 中出现的频率
  * $IDF(w) = \log \frac{N}{1 + n_w}$，其中 $N$ 是文档总数，$n_w$ 是包含词 $w$ 的文档数

* **例子**：

  * 语料：

    ```
    文档1: "我喜欢自然语言处理"
    文档2: "自然语言处理是人工智能的核心"
    ```
  * 在文档1中，词语“自然语言处理”的 TF 高，但它在多篇文档中也频繁出现 → IDF 低
  * 词语“喜欢”只在文档1出现 → IDF 高 → 更能代表文档1

* **优点**：

  * 简单高效
  * 适合提取高频的代表性词语

* **缺点**：

  * 忽略上下文和语义信息
  * 如果只有一个文档，IDF 退化（需要额外处理，如假设语料库）

---

### 2. **TextRank**

* **核心思想**：
  参考 PageRank 思路，将文本中的词作为图节点，基于窗口共现关系建立边，然后迭代更新节点的重要性分数，最后选择分数最高的若干词作为关键词。

* **例子**：

  * 语料：

    ```
    "自然语言处理是人工智能的重要分支"
    ```
  * 构建共现窗口（窗口=2），得到边：

    * (自然, 语言)、(语言, 处理)、(处理, 是)、(是, 人工)…
  * 经过迭代计算后，“自然语言处理”“人工智能” 重要性分数较高，被选为关键词。

* **优点**：

  * 无需外部语料库，纯无监督
  * 能够捕捉词语之间的语义相关性

* **缺点**：

  * 依赖窗口大小和迭代次数等超参数
  * 对短文本或极简句子效果有限
